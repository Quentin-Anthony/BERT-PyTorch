#!/bin/bash
#COBALT -t 30 
#COBALT -n 2
#COBALT -q full-node
#COBALT -A SuperBERT
#COBALT -O cobalt_logs/job
#COBALT --attrs enable_ssh=1

# Change to 2 for Phase 2 training
PHASE=1

if [[ "$PHASE" -eq 1 ]]; then
	CONFIG=config/bert_pretraining_phase1_config.json
	DATA=/lus/theta-fs0/projects/SuperBERT/datasets/wikicorpus_en/phase1
else
	CONFIG=config/bert_pretraining_phase2_config.json
	DATA=/lus/theta-fs0/projects/SuperBERT/datasets/wikicorpus_en/phase2
fi

OUTPUT_DIR=results/bert_pretraining

MASTER_RANK=$(head -n 1 $COBALT_NODEFILE)
RANKS=$(tr '\n' ' ' < $COBALT_NODEFILE)
NNODES=$(< $COBALT_NODEFILE wc -l)
NGPUS=8

# Launch the pytorch processes on each worker in NODEFILE
# Note we need to activate conda on the node as well
RANK=0
for NODE in $RANKS; do
	echo "Launching rank=$RANK, node=$NODE"
	if [[ "$RANK" -eq 0 ]]; then
		./scripts/launch_pretraining.sh \
			--ngpus $NGPUS --nnodes $NNODES --master $MASTER_RANK \
			--rank $RANK --config $CONFIG --input $DATA --output $OUTPUT_DIR &
	else
		ssh $NODE "cd $PWD; ./scripts/launch_pretraining.sh --ngpus $NGPUS --nnodes $NNODES --master $MASTER_RANK --rank $RANK --config $CONFIG --input $DATA --output $OUTPUT_DIR" &
	fi
	RANK=$((RANK+1))
done

wait

