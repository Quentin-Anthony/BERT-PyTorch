{
	"model_config_file": "config/roberta_large_config.json",
    "vocab_file": "/lus/theta-fs0/projects/SuperBERT/datasets/download/google_pretrained_weights/uncased_L-24_H-1024_A-16/vocab.txt",
	"fp16": true,
    "masked_token_fraction": 0.15,
	"max_predictions_per_seq": 80,
    "ignore_next_sentence": true,
	"learning_rate": 4e-4,
    "lr_decay": "linear",
	"warmup_proportion": 0.06,
	"global_batch_size": 8192,
	"local_batch_size": 16,
	"max_steps": 100000,
	"kfac": false,
	"kfac_inv_interval": 10,
	"kfac_factor_interval": 1
}
